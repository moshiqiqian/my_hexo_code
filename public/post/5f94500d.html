<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>学习周报第六周 | moshiqiqian</title><meta name="author" content="moshiqiqian"><meta name="copyright" content="moshiqiqian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="并行计算实验室学习周报">
<meta property="og:type" content="article">
<meta property="og:title" content="学习周报第六周">
<meta property="og:url" content="https://moshiqiqian.top/post/5f94500d.html">
<meta property="og:site_name" content="moshiqiqian">
<meta property="og:description" content="并行计算实验室学习周报">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://moshiqiqian.github.io/picx-images-hosting/%E7%BD%91%E7%AB%99/%E5%B0%81%E9%9D%A23.45zad85db.webp">
<meta property="article:published_time" content="2025-09-08T02:28:22.000Z">
<meta property="article:modified_time" content="2025-09-20T07:44:44.587Z">
<meta property="article:author" content="moshiqiqian">
<meta property="article:tag" content="人工智能">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://moshiqiqian.github.io/picx-images-hosting/%E7%BD%91%E7%AB%99/%E5%B0%81%E9%9D%A23.45zad85db.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "学习周报第六周",
  "url": "https://moshiqiqian.top/post/5f94500d.html",
  "image": "https://moshiqiqian.github.io/picx-images-hosting/网站/封面3.45zad85db.webp",
  "datePublished": "2025-09-08T02:28:22.000Z",
  "dateModified": "2025-09-20T07:44:44.587Z",
  "author": [
    {
      "@type": "Person",
      "name": "moshiqiqian",
      "url": "https://moshiqiqian.top"
    }
  ]
}</script><link rel="shortcut icon" href="/picture/favicon.ico"><link rel="canonical" href="https://moshiqiqian.top/post/5f94500d.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#1a1a1a')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const hour = new Date().getHours()
          const isNight = hour <= 7 || hour >= 19
          if (theme === undefined) isNight ? activateDarkMode() : activateLightMode()
          else theme === 'light' ? activateLightMode() : activateDarkMode()
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '学习周报第六周',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script src="https://cdn.jsdelivr.net/npm/echarts@5/dist/echarts.min.js"></script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_4892928_90poycgclrw.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.com/element-ui@2.15.6/lib/theme-chalk/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/picture/%E5%B0%81%E9%9D%A2top.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/picture/%E5%A4%B4%E5%83%8F.jpg" onerror="this.onerror=null;this.src='/picture/not_found.jpg'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa-solid fa-house"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-newspaper"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-bars"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa-solid fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa-solid fa-server"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-address-card"></i><span> 社交</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/comments/"><i class="fa-fw fa-solid fa-file-invoice"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/social/link/"><i class="fa-fw fa-solid fa-sign-hanging"></i><span> 友人帐</span></a></li><li><a class="site-page child" href="/social/shuoshuo/"><i class="fa-fw fa-solid fa-star-of-david"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-gem"></i><span> 关于</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/personal/about/"><i class="fa-fw fa-solid fa-tv"></i><span> 关于本站</span></a></li><li><a class="site-page child" href="/personal/person/"><i class="fa-fw fa-solid fa-blender"></i><span> 关于个人</span></a></li><li><a class="site-page child" href="/personal/MO/"><i class="fa-fw fa-solid fa-key"></i><span> MO的私货</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://moshiqiqian.github.io/picx-images-hosting/网站/封面3.45zad85db.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">moshiqiqian</span></a><a class="nav-page-title" href="/"><span class="site-name">学习周报第六周</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa-solid fa-house"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-newspaper"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-bars"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa-solid fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa-solid fa-server"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-address-card"></i><span> 社交</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/comments/"><i class="fa-fw fa-solid fa-file-invoice"></i><span> 留言板</span></a></li><li><a class="site-page child" href="/social/link/"><i class="fa-fw fa-solid fa-sign-hanging"></i><span> 友人帐</span></a></li><li><a class="site-page child" href="/social/shuoshuo/"><i class="fa-fw fa-solid fa-star-of-david"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-gem"></i><span> 关于</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/personal/about/"><i class="fa-fw fa-solid fa-tv"></i><span> 关于本站</span></a></li><li><a class="site-page child" href="/personal/person/"><i class="fa-fw fa-solid fa-blender"></i><span> 关于个人</span></a></li><li><a class="site-page child" href="/personal/MO/"><i class="fa-fw fa-solid fa-key"></i><span> MO的私货</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">学习周报第六周</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-08T02:28:22.000Z" title="发表于 2025-09-08 10:28:22">2025-09-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-20T07:44:44.587Z" title="更新于 2025-09-20 15:44:44">2025-09-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%91%A8%E6%8A%A5/">周报</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="twikoo_visitors"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="霍普菲尔德网络以及玻尔兹曼机周报"><a class="markdownIt-Anchor" href="#霍普菲尔德网络以及玻尔兹曼机周报"></a> 霍普菲尔德网络以及玻尔兹曼机周报</h2>
<h3 id="霍普菲尔德网络实验"><a class="markdownIt-Anchor" href="#霍普菲尔德网络实验"></a> 霍普菲尔德网络实验</h3>
<p><strong>代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 Matplotlib 字体以支持中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;Microsoft YaHei&#x27;</span>, <span class="string">&#x27;SimHei&#x27;</span>, <span class="string">&#x27;Arial Unicode MS&#x27;</span>] <span class="comment"># 尝试多个字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment"># 解决负号显示问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 霍普菲尔德网络核心函数 (这些函数内部处理的始终是1D数据) ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">patterns_1d</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    根据给定的1D模式集训练霍普菲尔德网络权重矩阵。</span></span><br><span class="line"><span class="string">    patterns_1d: 列表，每个元素是一个一维numpy数组（扁平化的模式）。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_neurons = patterns_1d[<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    w = np.zeros((num_neurons, num_neurons))</span><br><span class="line">    <span class="keyword">for</span> pattern <span class="keyword">in</span> patterns_1d:</span><br><span class="line">        pattern_col = pattern.reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 确保模式是列向量</span></span><br><span class="line">        w += np.dot(pattern_col, pattern_col.T)</span><br><span class="line">    np.fill_diagonal(w, <span class="number">0</span>) <span class="comment"># 自身连接设置为0</span></span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">E</span>(<span class="params">state_1d, w</span>):</span><br><span class="line"></span><br><span class="line">    state_col = state_1d.reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 确保状态是列向量</span></span><br><span class="line">    e = -<span class="number">0.5</span> * np.dot(state_col.T, np.dot(w, state_col))</span><br><span class="line">    <span class="keyword">return</span> e.item() <span class="comment"># 返回标量能量值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">state_1d, w, index</span>):</span><br><span class="line"></span><br><span class="line">    current_state_1d = np.copy(state_1d) <span class="comment"># 创建副本以避免直接修改传入的数组</span></span><br><span class="line">    net_input = np.dot(w[index, :], current_state_1d)</span><br><span class="line">    </span><br><span class="line">    new_state_val = current_state_1d[index] <span class="comment"># 默认为不改变</span></span><br><span class="line">    changed = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> net_input &gt; <span class="number">0</span>:</span><br><span class="line">        new_state_val = <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> net_input &lt; <span class="number">0</span>:</span><br><span class="line">        new_state_val = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果 net_input 为 0，保持状态不变</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> new_state_val != current_state_1d[index]:</span><br><span class="line">        changed = <span class="literal">True</span></span><br><span class="line">        current_state_1d[index] = new_state_val</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> current_state_1d, changed</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">work</span>(<span class="params">initial_state_1d, w, n_iterations=<span class="number">1000</span>, max_converge_sweeps=<span class="number">5</span></span>):</span><br><span class="line">   </span><br><span class="line">    current_state_1d = np.copy(initial_state_1d)</span><br><span class="line">    e_history = [E(initial_state_1d, w)]</span><br><span class="line">    num_neuron = initial_state_1d.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    no_change_count = <span class="number">0</span> </span><br><span class="line">    convergence_threshold = max_converge_sweeps * num_neuron</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iterations):</span><br><span class="line">        index = np.random.randint(num_neuron) <span class="comment"># 随机选择神经元进行更新</span></span><br><span class="line">        </span><br><span class="line">        current_state_1d, changed = update(current_state_1d, w, index)</span><br><span class="line">        </span><br><span class="line">        e_history.append(E(current_state_1d, w))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> changed:</span><br><span class="line">            no_change_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            no_change_count = <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> no_change_count &gt;= convergence_threshold:</span><br><span class="line">            <span class="keyword">break</span> <span class="comment"># 认为收敛</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> current_state_1d, e_history</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 辅助函数：处理1D和2D数据转换 ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_flatten_pattern</span>(<span class="params">pattern</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pattern.flatten()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_reshape_pattern</span>(<span class="params">pattern_1d, original_shape</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pattern_1d.reshape(original_shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_random_pattern</span>(<span class="params">shape</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.random.choice([-<span class="number">1</span>, <span class="number">1</span>], size=shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_noise</span>(<span class="params">pattern, noise_level=<span class="number">0.05</span></span>):</span><br><span class="line"></span><br><span class="line">    original_shape = pattern.shape</span><br><span class="line">    flat_pattern = _flatten_pattern(pattern)</span><br><span class="line">    noisy_flat_pattern = np.copy(flat_pattern)</span><br><span class="line">    </span><br><span class="line">    num_to_flip = <span class="built_in">int</span>(np.<span class="built_in">round</span>(<span class="built_in">len</span>(flat_pattern) * noise_level))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> num_to_flip == <span class="number">0</span> <span class="keyword">and</span> noise_level &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(flat_pattern) &gt; <span class="number">0</span>:</span><br><span class="line">        num_to_flip = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> num_to_flip &gt; <span class="number">0</span>:</span><br><span class="line">        flip_indices = np.random.choice(<span class="built_in">len</span>(flat_pattern), num_to_flip, replace=<span class="literal">False</span>)</span><br><span class="line">        noisy_flat_pattern[flip_indices] *= -<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> _reshape_pattern(noisy_flat_pattern, original_shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_overlap</span>(<span class="params">state1, state2</span>):</span><br><span class="line"></span><br><span class="line">    flat_state1 = _flatten_pattern(state1)</span><br><span class="line">    flat_state2 = _flatten_pattern(state2)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(flat_state1) == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(flat_state1, flat_state2) / <span class="built_in">len</span>(flat_state1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 模式存储能力测试实验 ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_storage_capacity</span>(<span class="params">pattern_shape, max_patterns_to_test, num_trials_per_pattern_count=<span class="number">50</span>, noise_level=<span class="number">0.05</span></span>):</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 确定总神经元数量 (N)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pattern_shape, <span class="built_in">int</span>):</span><br><span class="line">        num_neurons = pattern_shape</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(pattern_shape, <span class="built_in">tuple</span>):</span><br><span class="line">        num_neurons = np.prod(pattern_shape)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;pattern_shape 必须是整数（1D）或元组（2D）。&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 我们将测试的模式数量范围</span></span><br><span class="line">    pattern_counts = np.unique(np.linspace(<span class="number">1</span>, max_patterns_to_test, <span class="number">15</span>).astype(<span class="built_in">int</span>))</span><br><span class="line">    pattern_counts = pattern_counts[pattern_counts &lt;= num_neurons]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pattern_counts) == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;错误：模式数量范围无效，请检查 pattern_shape 和 max_patterns_to_test 参数。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    success_rates = []</span><br><span class="line">    theoretical_capacity_estimate = <span class="number">0.138</span> * num_neurons</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n--- 评估霍普菲尔德网络存储能力 ---&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;模式形状: <span class="subst">&#123;pattern_shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;总神经元数量 (N): <span class="subst">&#123;num_neurons&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;理论容量参考 (0.138 * N): <span class="subst">&#123;theoretical_capacity_estimate:<span class="number">.2</span>f&#125;</span> 个模式&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;噪声水平: <span class="subst">&#123;noise_level * <span class="number">100</span>:<span class="number">.0</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;每个模式数量重复试验次数: <span class="subst">&#123;num_trials_per_pattern_count&#125;</span>\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正在运行测试，请稍候...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p_count <span class="keyword">in</span> pattern_counts:</span><br><span class="line">        successful_recalls = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_trials_per_pattern_count):</span><br><span class="line">            <span class="keyword">if</span> p_count == <span class="number">0</span>: <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">            stored_patterns_original_shape = [create_random_pattern(pattern_shape) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(p_count)]</span><br><span class="line">           </span><br><span class="line">            stored_patterns_1d = [_flatten_pattern(p) <span class="keyword">for</span> p <span class="keyword">in</span> stored_patterns_original_shape]</span><br><span class="line">            w = train(stored_patterns_1d)</span><br><span class="line"></span><br><span class="line">           </span><br><span class="line">            <span class="keyword">for</span> original_pattern_original_shape <span class="keyword">in</span> stored_patterns_original_shape:</span><br><span class="line">                </span><br><span class="line">                initial_state_original_shape = add_noise(original_pattern_original_shape, noise_level)</span><br><span class="line">              </span><br><span class="line">                initial_state_1d = _flatten_pattern(initial_state_original_shape)</span><br><span class="line">                </span><br><span class="line">                final_state_1d, _ = work(initial_state_1d, w, n_iterations=num_neurons * <span class="number">100</span>, max_converge_sweeps=<span class="number">5</span>)</span><br><span class="line">            </span><br><span class="line">                overlap = get_overlap(final_state_1d, _flatten_pattern(original_pattern_original_shape))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">abs</span>(overlap) &gt; <span class="number">0.95</span>: </span><br><span class="line">                    successful_recalls += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">        total_attempts = p_count * num_trials_per_pattern_count</span><br><span class="line">        <span class="keyword">if</span> total_attempts &gt; <span class="number">0</span>:</span><br><span class="line">            success_rate = successful_recalls / total_attempts</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            success_rate = <span class="number">0</span> </span><br><span class="line">        </span><br><span class="line">        success_rates.append(success_rate)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  模式数量 P = <span class="subst">&#123;p_count:2d&#125;</span>: 召回成功率 = <span class="subst">&#123;success_rate:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 结果可视化 ---</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">    plt.plot(pattern_counts, success_rates, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> theoretical_capacity_estimate &gt; <span class="number">0</span>:</span><br><span class="line">        plt.axvline(x=theoretical_capacity_estimate, color=<span class="string">&#x27;red&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, </span><br><span class="line">                    label=<span class="string">f&#x27;理论容量参考 (≈<span class="subst">&#123;theoretical_capacity_estimate:<span class="number">.1</span>f&#125;</span>)&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.title(<span class="string">&#x27;霍普菲尔德网络模式存储能力&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;存储模式数量 (P)&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;平均召回成功率&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">    plt.ylim(-<span class="number">0.05</span>, <span class="number">1.05</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n评估完成。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 运行评估 ---</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># --- 参数调控 ---</span></span><br><span class="line">    <span class="comment"># 选择模式的形状</span></span><br><span class="line">    <span class="comment"># 1D 数据: pattern_shape_param = 50 (表示50个神经元)</span></span><br><span class="line">    <span class="comment"># 2D 数据 (例如: 10x10 图像): pattern_shape_param = (10, 10) (总神经元数 N=100)</span></span><br><span class="line">    pattern_shape_param = <span class="number">30</span> <span class="comment">#(10, 10) # 示例: 10x10 的2D图像，总共100个神经元</span></span><br><span class="line">    <span class="comment"># pattern_shape_param = 50 # 示例: 50个神经元的1D数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据总神经元数量（N）来调整 max_patterns_to_test</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pattern_shape_param, <span class="built_in">int</span>):</span><br><span class="line">        num_total_neurons = pattern_shape_param</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_total_neurons = np.prod(pattern_shape_param)</span><br><span class="line"></span><br><span class="line">    max_patterns_to_test_ratio = <span class="number">0.5</span> </span><br><span class="line">    max_patterns_to_test = <span class="built_in">int</span>(num_total_neurons * max_patterns_to_test_ratio)</span><br><span class="line">    <span class="keyword">if</span> max_patterns_to_test == <span class="number">0</span>: max_patterns_to_test = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    num_trials = <span class="number">100</span> </span><br><span class="line">    noise_level_param = <span class="number">0.05</span> </span><br><span class="line"></span><br><span class="line">    test_storage_capacity(</span><br><span class="line">        pattern_shape=pattern_shape_param,</span><br><span class="line">        max_patterns_to_test=max_patterns_to_test,</span><br><span class="line">        num_trials_per_pattern_count=num_trials,</span><br><span class="line">        noise_level=noise_level_param</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存储和显示2D图像</span></span><br><span class="line">   </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n--- 2D 模式召回演示 ---&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(pattern_shape_param, <span class="built_in">tuple</span>): <span class="comment"># 只有当设置为2D模式时才演示</span></span><br><span class="line">        demo_shape = pattern_shape_param</span><br><span class="line">        num_demo_neurons = np.prod(demo_shape)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 存储一个2D模式</span></span><br><span class="line">        original_2d_pattern = create_random_pattern(demo_shape)</span><br><span class="line">        <span class="comment"># 将2D模式扁平化进行训练</span></span><br><span class="line">        w_demo = train([_flatten_pattern(original_2d_pattern)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 添加噪声并扁平化作为初始状态</span></span><br><span class="line">        noisy_2d_input = add_noise(original_2d_pattern, noise_level=<span class="number">0.1</span>)</span><br><span class="line">        noisy_1d_input = _flatten_pattern(noisy_2d_input)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 运行网络</span></span><br><span class="line">        recalled_1d_pattern, _ = work(noisy_1d_input, w_demo, n_iterations=num_demo_neurons * <span class="number">100</span>, max_converge_sweeps=<span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 将召回的1D模式重新塑形回2D</span></span><br><span class="line">        recalled_2d_pattern = _reshape_pattern(recalled_1d_pattern, demo_shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示结果</span></span><br><span class="line">        fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">        axes[<span class="number">0</span>].imshow(original_2d_pattern, cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">        axes[<span class="number">0</span>].set_title(<span class="string">&#x27;原始模式&#x27;</span>)</span><br><span class="line">        axes[<span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        axes[<span class="number">1</span>].imshow(noisy_2d_input, cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">        axes[<span class="number">1</span>].set_title(<span class="string">&#x27;带噪声输入&#x27;</span>)</span><br><span class="line">        axes[<span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        axes[<span class="number">2</span>].imshow(recalled_2d_pattern, cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">        axes[<span class="number">2</span>].set_title(<span class="string">&#x27;召回模式&#x27;</span>)</span><br><span class="line">        axes[<span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.suptitle(<span class="string">f&quot;2D模式召回演示 (重叠度: <span class="subst">&#123;get_overlap(original_2d_pattern, recalled_2d_pattern):<span class="number">.3</span>f&#125;</span>)&quot;</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;当前模式形状为1D，跳过2D模式召回演示。&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">--- 评估霍普菲尔德网络存储能力 ---</span><br><span class="line">模式形状: 30</span><br><span class="line">总神经元数量 (N): 30</span><br><span class="line">理论容量参考 (0.138 * N): 4.14 个模式</span><br><span class="line">噪声水平: 5%</span><br><span class="line">每个模式数量重复试验次数: 100</span><br><span class="line"></span><br><span class="line">正在运行测试，请稍候...</span><br><span class="line">  模式数量 P =  1: 召回成功率 = 1.000</span><br><span class="line">  模式数量 P =  2: 召回成功率 = 0.995</span><br><span class="line">  模式数量 P =  3: 召回成功率 = 0.990</span><br><span class="line">  模式数量 P =  4: 召回成功率 = 0.968</span><br><span class="line">  模式数量 P =  5: 召回成功率 = 0.828</span><br><span class="line">  模式数量 P =  6: 召回成功率 = 0.735</span><br><span class="line">  模式数量 P =  7: 召回成功率 = 0.549</span><br><span class="line">  模式数量 P =  8: 召回成功率 = 0.535</span><br><span class="line">  模式数量 P =  9: 召回成功率 = 0.308</span><br><span class="line">  模式数量 P = 10: 召回成功率 = 0.256</span><br><span class="line">  模式数量 P = 11: 召回成功率 = 0.145</span><br><span class="line">  模式数量 P = 12: 召回成功率 = 0.116</span><br><span class="line">  模式数量 P = 13: 召回成功率 = 0.056</span><br><span class="line">  模式数量 P = 14: 召回成功率 = 0.044</span><br><span class="line">  模式数量 P = 15: 召回成功率 = 0.023</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/%E5%91%A8%E6%8A%A5/image.6bhf8ds5o7.webp" alt="image" /></p>
<p><strong>总结</strong>：</p>
<p>1.重新更新代码后，霍普菲尔德网络的存储容量与标准数据吻合，重新查看原本的代码，发现主要是因为最开始写的work函数中选择随机的神经元更新，但是判断收敛的条件不合理与神经元数量少，训练数据单一，这会导致后续实验的时候，降低霍普菲尔德网络的准确性。所以将更新的模式重新优化，最终得出实验结果。在超过存储极限后，召回率断崖式下降。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原本的代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">work</span>(<span class="params">initial_state,w,n = <span class="number">1000</span></span>):</span><br><span class="line">    current_state = np.copy(initial_state)</span><br><span class="line">    e_history = [E(initial_state,w)]</span><br><span class="line">    num_neuron = initial_state.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    state_history = [np.copy(initial_state)] </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        index = np.random.randint(num_neuron) </span><br><span class="line">        current_state,changed = update(current_state,w,index)</span><br><span class="line">        e_history.append(E(current_state, w))</span><br><span class="line">        state_history.append(np.copy(current_state)) </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> current_state, e_history, state_history</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改后的代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">work</span>(<span class="params">initial_state_1d, w, n_iterations=<span class="number">1000</span>, max_converge_sweeps=<span class="number">5</span></span>):</span><br><span class="line">   </span><br><span class="line">    current_state_1d = np.copy(initial_state_1d)</span><br><span class="line">    e_history = [E(initial_state_1d, w)]</span><br><span class="line">    num_neuron = initial_state_1d.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    no_change_count = <span class="number">0</span> </span><br><span class="line">    convergence_threshold = max_converge_sweeps * num_neuron</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iterations):</span><br><span class="line">        index = np.random.randint(num_neuron) </span><br><span class="line">        </span><br><span class="line">        current_state_1d, changed = update(current_state_1d, w, index)</span><br><span class="line">        </span><br><span class="line">        e_history.append(E(current_state_1d, w))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> changed:</span><br><span class="line">            no_change_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            no_change_count = <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> no_change_count &gt;= convergence_threshold: <span class="comment"># 根据神经元数量确定收敛的条件</span></span><br><span class="line">            <span class="keyword">break</span> </span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> current_state_1d, e_history</span><br></pre></td></tr></table></figure>
<h3 id="玻尔兹曼机的相关内容"><a class="markdownIt-Anchor" href="#玻尔兹曼机的相关内容"></a> 玻尔兹曼机的相关内容</h3>
<p>详细看网站：<a target="_blank" rel="noopener" href="https://www.moshiqiqian.top/post/bb733ff7.html">玻尔兹曼机 | moshiqiqian</a></p>
<h3 id="下周计划"><a class="markdownIt-Anchor" href="#下周计划"></a> 下周计划</h3>
<p>1.进一步学习受限玻尔兹曼机</p>
<p>2.完成受限玻尔兹曼机的代码实现</p>
<p>3.学习QDF ,QDA相关知识</p>
<h3 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h3>
<ol>
<li>
<p>正所谓赫布学习不分正反，我了解到对比赫布学习也不分正反。</p>
<p>在数学上：可以理解为同号相乘必然为正，异号相乘为负，所以神经元的状态相反，那么权重完全一致。</p>
<ul>
<li>
<p>但是在能量景观上，该如何理解，是同一个谷/峰？还是一个完全相反的谷/峰？他会在哪里？整个能量景观的一部分？还是不存在的只是虚构的？</p>
</li>
<li>
<p>如果是生成了一个现实存在的相反，那么是否可以认为，能量景观是守恒的，一部分在水平面降低了，那么会有另一部分在水平面升高了？</p>
</li>
<li>
<p>如果是守恒的，那么玻尔兹曼机中的能量景观中的谷是否会比霍普菲尔德网络更陡峭（同样的模式）？</p>
</li>
<li>
<p>我们接下来提升人工智能的效率，能否致力于极致的拉高非正确的谷/峰，这样正确的能量景观将会很陡峭，然后忽略其中的局部最小值（因为能量景观的变形，他的带来的阻力会很小，我们给小球一个初速度，让他可以用惯性来突破这个局部最小值）。</p>
</li>
</ul>
</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://moshiqiqian.top">moshiqiqian</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://moshiqiqian.top/post/5f94500d.html">https://moshiqiqian.top/post/5f94500d.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://moshiqiqian.top" target="_blank">moshiqiqian</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/picture/weixin.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/picture/weixin.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/picture/zhifubao.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/picture/zhifubao.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/post/3a9a1bd4.html" title="学习周报第五周"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面1.2yyng5nc4o.webp" onerror="onerror=null;src='/picture/not_found.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">学习周报第五周</div></div><div class="info-2"><div class="info-item-1">并行计算实验室学习周报</div></div></div></a><a class="pagination-related" href="/post/8d942792.html" title="学习周报第七周"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面8.7pl83183g.webp" onerror="onerror=null;src='/picture/not_found.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">学习周报第七周</div></div><div class="info-2"><div class="info-item-1">并行计算实验室学习周报</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%8D%E6%99%AE%E8%8F%B2%E5%B0%94%E5%BE%B7%E7%BD%91%E7%BB%9C%E4%BB%A5%E5%8F%8A%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA%E5%91%A8%E6%8A%A5"><span class="toc-number">1.</span> <span class="toc-text"> 霍普菲尔德网络以及玻尔兹曼机周报</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9C%8D%E6%99%AE%E8%8F%B2%E5%B0%94%E5%BE%B7%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.1.</span> <span class="toc-text"> 霍普菲尔德网络实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA%E7%9A%84%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9"><span class="toc-number">1.2.</span> <span class="toc-text"> 玻尔兹曼机的相关内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E5%91%A8%E8%AE%A1%E5%88%92"><span class="toc-number">1.3.</span> <span class="toc-text"> 下周计划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.</span> <span class="toc-text"> 问题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By moshiqiqian</span></div><div class="footer_custom_text">mo的小站</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-teal-mu.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = (el = document, path = location.pathname) => {
    twikoo.init({
      el: el.querySelector('#twikoo-wrap'),
      envId: 'https://twikoo-teal-mu.vercel.app/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      },
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    

    isShuoshuo && (window.shuoshuoComment.destroyTwikoo = () => {
      if (el.children.length) {
        el.innerHTML = ''
        el.classList.add('no-comment')
      }
    })
  }

  const loadTwikoo = (el, path) => {
    if (typeof twikoo === 'object') setTimeout(() => init(el, path), 0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(() => init(el, path))
  }

  if (isShuoshuo) {
    'Twikoo' === 'Twikoo'
      ? window.shuoshuoComment = { loadComment: loadTwikoo }
      : window.loadOtherComment = loadTwikoo
    return
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script defer src="/js/light.js"></script><script defer src="/js/universe.js"></script><canvas id="universe"></canvas><script defer src="/js/cursor.js"></script><script defer src="/js/emoji.js"></script><script defer src="https://unpkg.com/vue@2.6.14/dist/vue.min.js"></script><script defer src="https://unpkg.com/element-ui@2.15.6/lib/index.js"></script><script defer src="/js/formal.js"></script><script defer src="/js/console.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '1s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="post/bb733ff7.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面1.2yyng5nc4o.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-07-18</span><a class="blog-slider__title" href="post/bb733ff7.html" alt="">玻尔兹曼机</a><div class="blog-slider__text">玻尔兹曼机的基础概念以及原理介绍</div><a class="blog-slider__button" href="post/bb733ff7.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="post/624c7376.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面5.45hyorc8qc.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-10-08</span><a class="blog-slider__title" href="post/624c7376.html" alt="">图灵机</a><div class="blog-slider__text">图灵机家族的相关介绍</div><a class="blog-slider__button" href="post/624c7376.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="post/cbdf0372.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面12.7eh2lezqdf.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-24</span><a class="blog-slider__title" href="post/cbdf0372.html" alt="">霍普菲尔德网络</a><div class="blog-slider__text">霍普菲尔德网络的原理以及公式解释</div><a class="blog-slider__button" href="post/cbdf0372.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="post/7d6919a5.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moshiqiqian.github.io/picx-images-hosting/网站/封面3.45zad85db.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-28</span><a class="blog-slider__title" href="post/7d6919a5.html" alt="">超好用永久免费图床</a><div class="blog-slider__text">计算机的基础常识,帮助你快速度过计算机小白时期!</div><a class="blog-slider__button" href="post/7d6919a5.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>